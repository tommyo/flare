//
// Licensed to the Apache Software Foundation (ASF) under one or more
// contributor license agreements.  See the NOTICE file distributed with
// this work for additional information regarding copyright ownership.
// The ASF licenses this file to You under the Apache License, Version 2.0
// (the "License"); you may not use this file except in compliance with
// the License.  You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by protoc-gen-connect-go. DO NOT EDIT.
//
// Source: spark/connect/base.proto

package protoconnect

import (
	connect "connectrpc.com/connect"
	context "context"
	errors "errors"
	proto "github.com/tommyo/flare/proto"
	http "net/http"
	strings "strings"
)

// This is a compile-time assertion to ensure that this generated file and the connect package are
// compatible. If you get a compiler error that this constant is not defined, this code was
// generated with a version of connect newer than the one compiled into your binary. You can fix the
// problem by either regenerating this code with an older version of connect or updating the connect
// version compiled into your binary.
const _ = connect.IsAtLeastVersion1_13_0

const (
	// SparkConnectServiceName is the fully-qualified name of the SparkConnectService service.
	SparkConnectServiceName = "spark.connect.SparkConnectService"
)

// These constants are the fully-qualified names of the RPCs defined in this package. They're
// exposed at runtime as Spec.Procedure and as the final two segments of the HTTP route.
//
// Note that these are different from the fully-qualified method names used by
// google.golang.org/protobuf/reflect/protoreflect. To convert from these constants to
// reflection-formatted method names, remove the leading slash and convert the remaining slash to a
// period.
const (
	// SparkConnectServiceExecutePlanProcedure is the fully-qualified name of the SparkConnectService's
	// ExecutePlan RPC.
	SparkConnectServiceExecutePlanProcedure = "/spark.connect.SparkConnectService/ExecutePlan"
	// SparkConnectServiceAnalyzePlanProcedure is the fully-qualified name of the SparkConnectService's
	// AnalyzePlan RPC.
	SparkConnectServiceAnalyzePlanProcedure = "/spark.connect.SparkConnectService/AnalyzePlan"
	// SparkConnectServiceConfigProcedure is the fully-qualified name of the SparkConnectService's
	// Config RPC.
	SparkConnectServiceConfigProcedure = "/spark.connect.SparkConnectService/Config"
	// SparkConnectServiceAddArtifactsProcedure is the fully-qualified name of the SparkConnectService's
	// AddArtifacts RPC.
	SparkConnectServiceAddArtifactsProcedure = "/spark.connect.SparkConnectService/AddArtifacts"
	// SparkConnectServiceArtifactStatusProcedure is the fully-qualified name of the
	// SparkConnectService's ArtifactStatus RPC.
	SparkConnectServiceArtifactStatusProcedure = "/spark.connect.SparkConnectService/ArtifactStatus"
	// SparkConnectServiceInterruptProcedure is the fully-qualified name of the SparkConnectService's
	// Interrupt RPC.
	SparkConnectServiceInterruptProcedure = "/spark.connect.SparkConnectService/Interrupt"
	// SparkConnectServiceReattachExecuteProcedure is the fully-qualified name of the
	// SparkConnectService's ReattachExecute RPC.
	SparkConnectServiceReattachExecuteProcedure = "/spark.connect.SparkConnectService/ReattachExecute"
	// SparkConnectServiceReleaseExecuteProcedure is the fully-qualified name of the
	// SparkConnectService's ReleaseExecute RPC.
	SparkConnectServiceReleaseExecuteProcedure = "/spark.connect.SparkConnectService/ReleaseExecute"
	// SparkConnectServiceReleaseSessionProcedure is the fully-qualified name of the
	// SparkConnectService's ReleaseSession RPC.
	SparkConnectServiceReleaseSessionProcedure = "/spark.connect.SparkConnectService/ReleaseSession"
	// SparkConnectServiceFetchErrorDetailsProcedure is the fully-qualified name of the
	// SparkConnectService's FetchErrorDetails RPC.
	SparkConnectServiceFetchErrorDetailsProcedure = "/spark.connect.SparkConnectService/FetchErrorDetails"
)

// These variables are the protoreflect.Descriptor objects for the RPCs defined in this package.
var (
	sparkConnectServiceServiceDescriptor                 = proto.File_spark_connect_base_proto.Services().ByName("SparkConnectService")
	sparkConnectServiceExecutePlanMethodDescriptor       = sparkConnectServiceServiceDescriptor.Methods().ByName("ExecutePlan")
	sparkConnectServiceAnalyzePlanMethodDescriptor       = sparkConnectServiceServiceDescriptor.Methods().ByName("AnalyzePlan")
	sparkConnectServiceConfigMethodDescriptor            = sparkConnectServiceServiceDescriptor.Methods().ByName("Config")
	sparkConnectServiceAddArtifactsMethodDescriptor      = sparkConnectServiceServiceDescriptor.Methods().ByName("AddArtifacts")
	sparkConnectServiceArtifactStatusMethodDescriptor    = sparkConnectServiceServiceDescriptor.Methods().ByName("ArtifactStatus")
	sparkConnectServiceInterruptMethodDescriptor         = sparkConnectServiceServiceDescriptor.Methods().ByName("Interrupt")
	sparkConnectServiceReattachExecuteMethodDescriptor   = sparkConnectServiceServiceDescriptor.Methods().ByName("ReattachExecute")
	sparkConnectServiceReleaseExecuteMethodDescriptor    = sparkConnectServiceServiceDescriptor.Methods().ByName("ReleaseExecute")
	sparkConnectServiceReleaseSessionMethodDescriptor    = sparkConnectServiceServiceDescriptor.Methods().ByName("ReleaseSession")
	sparkConnectServiceFetchErrorDetailsMethodDescriptor = sparkConnectServiceServiceDescriptor.Methods().ByName("FetchErrorDetails")
)

// SparkConnectServiceClient is a client for the spark.connect.SparkConnectService service.
type SparkConnectServiceClient interface {
	// Executes a request that contains the query and returns a stream of [[Response]].
	//
	// It is guaranteed that there is at least one ARROW batch returned even if the result set is empty.
	ExecutePlan(context.Context, *connect.Request[proto.ExecutePlanRequest]) (*connect.ServerStreamForClient[proto.ExecutePlanResponse], error)
	// Analyzes a query and returns a [[AnalyzeResponse]] containing metadata about the query.
	AnalyzePlan(context.Context, *connect.Request[proto.AnalyzePlanRequest]) (*connect.Response[proto.AnalyzePlanResponse], error)
	// Update or fetch the configurations and returns a [[ConfigResponse]] containing the result.
	Config(context.Context, *connect.Request[proto.ConfigRequest]) (*connect.Response[proto.ConfigResponse], error)
	// Add artifacts to the session and returns a [[AddArtifactsResponse]] containing metadata about
	// the added artifacts.
	AddArtifacts(context.Context) *connect.ClientStreamForClient[proto.AddArtifactsRequest, proto.AddArtifactsResponse]
	// Check statuses of artifacts in the session and returns them in a [[ArtifactStatusesResponse]]
	ArtifactStatus(context.Context, *connect.Request[proto.ArtifactStatusesRequest]) (*connect.Response[proto.ArtifactStatusesResponse], error)
	// Interrupts running executions
	Interrupt(context.Context, *connect.Request[proto.InterruptRequest]) (*connect.Response[proto.InterruptResponse], error)
	// Reattach to an existing reattachable execution.
	// The ExecutePlan must have been started with ReattachOptions.reattachable=true.
	// If the ExecutePlanResponse stream ends without a ResultComplete message, there is more to
	// continue. If there is a ResultComplete, the client should use ReleaseExecute with
	ReattachExecute(context.Context, *connect.Request[proto.ReattachExecuteRequest]) (*connect.ServerStreamForClient[proto.ExecutePlanResponse], error)
	// Release an reattachable execution, or parts thereof.
	// The ExecutePlan must have been started with ReattachOptions.reattachable=true.
	// Non reattachable executions are released automatically and immediately after the ExecutePlan
	// RPC and ReleaseExecute may not be used.
	ReleaseExecute(context.Context, *connect.Request[proto.ReleaseExecuteRequest]) (*connect.Response[proto.ReleaseExecuteResponse], error)
	// Release a session.
	// All the executions in the session will be released. Any further requests for the session with
	// that session_id for the given user_id will fail. If the session didn't exist or was already
	// released, this is a noop.
	ReleaseSession(context.Context, *connect.Request[proto.ReleaseSessionRequest]) (*connect.Response[proto.ReleaseSessionResponse], error)
	// FetchErrorDetails retrieves the matched exception with details based on a provided error id.
	FetchErrorDetails(context.Context, *connect.Request[proto.FetchErrorDetailsRequest]) (*connect.Response[proto.FetchErrorDetailsResponse], error)
}

// NewSparkConnectServiceClient constructs a client for the spark.connect.SparkConnectService
// service. By default, it uses the Connect protocol with the binary Protobuf Codec, asks for
// gzipped responses, and sends uncompressed requests. To use the gRPC or gRPC-Web protocols, supply
// the connect.WithGRPC() or connect.WithGRPCWeb() options.
//
// The URL supplied here should be the base URL for the Connect or gRPC server (for example,
// http://api.acme.com or https://acme.com/grpc).
func NewSparkConnectServiceClient(httpClient connect.HTTPClient, baseURL string, opts ...connect.ClientOption) SparkConnectServiceClient {
	baseURL = strings.TrimRight(baseURL, "/")
	return &sparkConnectServiceClient{
		executePlan: connect.NewClient[proto.ExecutePlanRequest, proto.ExecutePlanResponse](
			httpClient,
			baseURL+SparkConnectServiceExecutePlanProcedure,
			connect.WithSchema(sparkConnectServiceExecutePlanMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		analyzePlan: connect.NewClient[proto.AnalyzePlanRequest, proto.AnalyzePlanResponse](
			httpClient,
			baseURL+SparkConnectServiceAnalyzePlanProcedure,
			connect.WithSchema(sparkConnectServiceAnalyzePlanMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		config: connect.NewClient[proto.ConfigRequest, proto.ConfigResponse](
			httpClient,
			baseURL+SparkConnectServiceConfigProcedure,
			connect.WithSchema(sparkConnectServiceConfigMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		addArtifacts: connect.NewClient[proto.AddArtifactsRequest, proto.AddArtifactsResponse](
			httpClient,
			baseURL+SparkConnectServiceAddArtifactsProcedure,
			connect.WithSchema(sparkConnectServiceAddArtifactsMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		artifactStatus: connect.NewClient[proto.ArtifactStatusesRequest, proto.ArtifactStatusesResponse](
			httpClient,
			baseURL+SparkConnectServiceArtifactStatusProcedure,
			connect.WithSchema(sparkConnectServiceArtifactStatusMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		interrupt: connect.NewClient[proto.InterruptRequest, proto.InterruptResponse](
			httpClient,
			baseURL+SparkConnectServiceInterruptProcedure,
			connect.WithSchema(sparkConnectServiceInterruptMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		reattachExecute: connect.NewClient[proto.ReattachExecuteRequest, proto.ExecutePlanResponse](
			httpClient,
			baseURL+SparkConnectServiceReattachExecuteProcedure,
			connect.WithSchema(sparkConnectServiceReattachExecuteMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		releaseExecute: connect.NewClient[proto.ReleaseExecuteRequest, proto.ReleaseExecuteResponse](
			httpClient,
			baseURL+SparkConnectServiceReleaseExecuteProcedure,
			connect.WithSchema(sparkConnectServiceReleaseExecuteMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		releaseSession: connect.NewClient[proto.ReleaseSessionRequest, proto.ReleaseSessionResponse](
			httpClient,
			baseURL+SparkConnectServiceReleaseSessionProcedure,
			connect.WithSchema(sparkConnectServiceReleaseSessionMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
		fetchErrorDetails: connect.NewClient[proto.FetchErrorDetailsRequest, proto.FetchErrorDetailsResponse](
			httpClient,
			baseURL+SparkConnectServiceFetchErrorDetailsProcedure,
			connect.WithSchema(sparkConnectServiceFetchErrorDetailsMethodDescriptor),
			connect.WithClientOptions(opts...),
		),
	}
}

// sparkConnectServiceClient implements SparkConnectServiceClient.
type sparkConnectServiceClient struct {
	executePlan       *connect.Client[proto.ExecutePlanRequest, proto.ExecutePlanResponse]
	analyzePlan       *connect.Client[proto.AnalyzePlanRequest, proto.AnalyzePlanResponse]
	config            *connect.Client[proto.ConfigRequest, proto.ConfigResponse]
	addArtifacts      *connect.Client[proto.AddArtifactsRequest, proto.AddArtifactsResponse]
	artifactStatus    *connect.Client[proto.ArtifactStatusesRequest, proto.ArtifactStatusesResponse]
	interrupt         *connect.Client[proto.InterruptRequest, proto.InterruptResponse]
	reattachExecute   *connect.Client[proto.ReattachExecuteRequest, proto.ExecutePlanResponse]
	releaseExecute    *connect.Client[proto.ReleaseExecuteRequest, proto.ReleaseExecuteResponse]
	releaseSession    *connect.Client[proto.ReleaseSessionRequest, proto.ReleaseSessionResponse]
	fetchErrorDetails *connect.Client[proto.FetchErrorDetailsRequest, proto.FetchErrorDetailsResponse]
}

// ExecutePlan calls spark.connect.SparkConnectService.ExecutePlan.
func (c *sparkConnectServiceClient) ExecutePlan(ctx context.Context, req *connect.Request[proto.ExecutePlanRequest]) (*connect.ServerStreamForClient[proto.ExecutePlanResponse], error) {
	return c.executePlan.CallServerStream(ctx, req)
}

// AnalyzePlan calls spark.connect.SparkConnectService.AnalyzePlan.
func (c *sparkConnectServiceClient) AnalyzePlan(ctx context.Context, req *connect.Request[proto.AnalyzePlanRequest]) (*connect.Response[proto.AnalyzePlanResponse], error) {
	return c.analyzePlan.CallUnary(ctx, req)
}

// Config calls spark.connect.SparkConnectService.Config.
func (c *sparkConnectServiceClient) Config(ctx context.Context, req *connect.Request[proto.ConfigRequest]) (*connect.Response[proto.ConfigResponse], error) {
	return c.config.CallUnary(ctx, req)
}

// AddArtifacts calls spark.connect.SparkConnectService.AddArtifacts.
func (c *sparkConnectServiceClient) AddArtifacts(ctx context.Context) *connect.ClientStreamForClient[proto.AddArtifactsRequest, proto.AddArtifactsResponse] {
	return c.addArtifacts.CallClientStream(ctx)
}

// ArtifactStatus calls spark.connect.SparkConnectService.ArtifactStatus.
func (c *sparkConnectServiceClient) ArtifactStatus(ctx context.Context, req *connect.Request[proto.ArtifactStatusesRequest]) (*connect.Response[proto.ArtifactStatusesResponse], error) {
	return c.artifactStatus.CallUnary(ctx, req)
}

// Interrupt calls spark.connect.SparkConnectService.Interrupt.
func (c *sparkConnectServiceClient) Interrupt(ctx context.Context, req *connect.Request[proto.InterruptRequest]) (*connect.Response[proto.InterruptResponse], error) {
	return c.interrupt.CallUnary(ctx, req)
}

// ReattachExecute calls spark.connect.SparkConnectService.ReattachExecute.
func (c *sparkConnectServiceClient) ReattachExecute(ctx context.Context, req *connect.Request[proto.ReattachExecuteRequest]) (*connect.ServerStreamForClient[proto.ExecutePlanResponse], error) {
	return c.reattachExecute.CallServerStream(ctx, req)
}

// ReleaseExecute calls spark.connect.SparkConnectService.ReleaseExecute.
func (c *sparkConnectServiceClient) ReleaseExecute(ctx context.Context, req *connect.Request[proto.ReleaseExecuteRequest]) (*connect.Response[proto.ReleaseExecuteResponse], error) {
	return c.releaseExecute.CallUnary(ctx, req)
}

// ReleaseSession calls spark.connect.SparkConnectService.ReleaseSession.
func (c *sparkConnectServiceClient) ReleaseSession(ctx context.Context, req *connect.Request[proto.ReleaseSessionRequest]) (*connect.Response[proto.ReleaseSessionResponse], error) {
	return c.releaseSession.CallUnary(ctx, req)
}

// FetchErrorDetails calls spark.connect.SparkConnectService.FetchErrorDetails.
func (c *sparkConnectServiceClient) FetchErrorDetails(ctx context.Context, req *connect.Request[proto.FetchErrorDetailsRequest]) (*connect.Response[proto.FetchErrorDetailsResponse], error) {
	return c.fetchErrorDetails.CallUnary(ctx, req)
}

// SparkConnectServiceHandler is an implementation of the spark.connect.SparkConnectService service.
type SparkConnectServiceHandler interface {
	// Executes a request that contains the query and returns a stream of [[Response]].
	//
	// It is guaranteed that there is at least one ARROW batch returned even if the result set is empty.
	ExecutePlan(context.Context, *connect.Request[proto.ExecutePlanRequest], *connect.ServerStream[proto.ExecutePlanResponse]) error
	// Analyzes a query and returns a [[AnalyzeResponse]] containing metadata about the query.
	AnalyzePlan(context.Context, *connect.Request[proto.AnalyzePlanRequest]) (*connect.Response[proto.AnalyzePlanResponse], error)
	// Update or fetch the configurations and returns a [[ConfigResponse]] containing the result.
	Config(context.Context, *connect.Request[proto.ConfigRequest]) (*connect.Response[proto.ConfigResponse], error)
	// Add artifacts to the session and returns a [[AddArtifactsResponse]] containing metadata about
	// the added artifacts.
	AddArtifacts(context.Context, *connect.ClientStream[proto.AddArtifactsRequest]) (*connect.Response[proto.AddArtifactsResponse], error)
	// Check statuses of artifacts in the session and returns them in a [[ArtifactStatusesResponse]]
	ArtifactStatus(context.Context, *connect.Request[proto.ArtifactStatusesRequest]) (*connect.Response[proto.ArtifactStatusesResponse], error)
	// Interrupts running executions
	Interrupt(context.Context, *connect.Request[proto.InterruptRequest]) (*connect.Response[proto.InterruptResponse], error)
	// Reattach to an existing reattachable execution.
	// The ExecutePlan must have been started with ReattachOptions.reattachable=true.
	// If the ExecutePlanResponse stream ends without a ResultComplete message, there is more to
	// continue. If there is a ResultComplete, the client should use ReleaseExecute with
	ReattachExecute(context.Context, *connect.Request[proto.ReattachExecuteRequest], *connect.ServerStream[proto.ExecutePlanResponse]) error
	// Release an reattachable execution, or parts thereof.
	// The ExecutePlan must have been started with ReattachOptions.reattachable=true.
	// Non reattachable executions are released automatically and immediately after the ExecutePlan
	// RPC and ReleaseExecute may not be used.
	ReleaseExecute(context.Context, *connect.Request[proto.ReleaseExecuteRequest]) (*connect.Response[proto.ReleaseExecuteResponse], error)
	// Release a session.
	// All the executions in the session will be released. Any further requests for the session with
	// that session_id for the given user_id will fail. If the session didn't exist or was already
	// released, this is a noop.
	ReleaseSession(context.Context, *connect.Request[proto.ReleaseSessionRequest]) (*connect.Response[proto.ReleaseSessionResponse], error)
	// FetchErrorDetails retrieves the matched exception with details based on a provided error id.
	FetchErrorDetails(context.Context, *connect.Request[proto.FetchErrorDetailsRequest]) (*connect.Response[proto.FetchErrorDetailsResponse], error)
}

// NewSparkConnectServiceHandler builds an HTTP handler from the service implementation. It returns
// the path on which to mount the handler and the handler itself.
//
// By default, handlers support the Connect, gRPC, and gRPC-Web protocols with the binary Protobuf
// and JSON codecs. They also support gzip compression.
func NewSparkConnectServiceHandler(svc SparkConnectServiceHandler, opts ...connect.HandlerOption) (string, http.Handler) {
	sparkConnectServiceExecutePlanHandler := connect.NewServerStreamHandler(
		SparkConnectServiceExecutePlanProcedure,
		svc.ExecutePlan,
		connect.WithSchema(sparkConnectServiceExecutePlanMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	sparkConnectServiceAnalyzePlanHandler := connect.NewUnaryHandler(
		SparkConnectServiceAnalyzePlanProcedure,
		svc.AnalyzePlan,
		connect.WithSchema(sparkConnectServiceAnalyzePlanMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	sparkConnectServiceConfigHandler := connect.NewUnaryHandler(
		SparkConnectServiceConfigProcedure,
		svc.Config,
		connect.WithSchema(sparkConnectServiceConfigMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	sparkConnectServiceAddArtifactsHandler := connect.NewClientStreamHandler(
		SparkConnectServiceAddArtifactsProcedure,
		svc.AddArtifacts,
		connect.WithSchema(sparkConnectServiceAddArtifactsMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	sparkConnectServiceArtifactStatusHandler := connect.NewUnaryHandler(
		SparkConnectServiceArtifactStatusProcedure,
		svc.ArtifactStatus,
		connect.WithSchema(sparkConnectServiceArtifactStatusMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	sparkConnectServiceInterruptHandler := connect.NewUnaryHandler(
		SparkConnectServiceInterruptProcedure,
		svc.Interrupt,
		connect.WithSchema(sparkConnectServiceInterruptMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	sparkConnectServiceReattachExecuteHandler := connect.NewServerStreamHandler(
		SparkConnectServiceReattachExecuteProcedure,
		svc.ReattachExecute,
		connect.WithSchema(sparkConnectServiceReattachExecuteMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	sparkConnectServiceReleaseExecuteHandler := connect.NewUnaryHandler(
		SparkConnectServiceReleaseExecuteProcedure,
		svc.ReleaseExecute,
		connect.WithSchema(sparkConnectServiceReleaseExecuteMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	sparkConnectServiceReleaseSessionHandler := connect.NewUnaryHandler(
		SparkConnectServiceReleaseSessionProcedure,
		svc.ReleaseSession,
		connect.WithSchema(sparkConnectServiceReleaseSessionMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	sparkConnectServiceFetchErrorDetailsHandler := connect.NewUnaryHandler(
		SparkConnectServiceFetchErrorDetailsProcedure,
		svc.FetchErrorDetails,
		connect.WithSchema(sparkConnectServiceFetchErrorDetailsMethodDescriptor),
		connect.WithHandlerOptions(opts...),
	)
	return "/spark.connect.SparkConnectService/", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		switch r.URL.Path {
		case SparkConnectServiceExecutePlanProcedure:
			sparkConnectServiceExecutePlanHandler.ServeHTTP(w, r)
		case SparkConnectServiceAnalyzePlanProcedure:
			sparkConnectServiceAnalyzePlanHandler.ServeHTTP(w, r)
		case SparkConnectServiceConfigProcedure:
			sparkConnectServiceConfigHandler.ServeHTTP(w, r)
		case SparkConnectServiceAddArtifactsProcedure:
			sparkConnectServiceAddArtifactsHandler.ServeHTTP(w, r)
		case SparkConnectServiceArtifactStatusProcedure:
			sparkConnectServiceArtifactStatusHandler.ServeHTTP(w, r)
		case SparkConnectServiceInterruptProcedure:
			sparkConnectServiceInterruptHandler.ServeHTTP(w, r)
		case SparkConnectServiceReattachExecuteProcedure:
			sparkConnectServiceReattachExecuteHandler.ServeHTTP(w, r)
		case SparkConnectServiceReleaseExecuteProcedure:
			sparkConnectServiceReleaseExecuteHandler.ServeHTTP(w, r)
		case SparkConnectServiceReleaseSessionProcedure:
			sparkConnectServiceReleaseSessionHandler.ServeHTTP(w, r)
		case SparkConnectServiceFetchErrorDetailsProcedure:
			sparkConnectServiceFetchErrorDetailsHandler.ServeHTTP(w, r)
		default:
			http.NotFound(w, r)
		}
	})
}

// UnimplementedSparkConnectServiceHandler returns CodeUnimplemented from all methods.
type UnimplementedSparkConnectServiceHandler struct{}

func (UnimplementedSparkConnectServiceHandler) ExecutePlan(context.Context, *connect.Request[proto.ExecutePlanRequest], *connect.ServerStream[proto.ExecutePlanResponse]) error {
	return connect.NewError(connect.CodeUnimplemented, errors.New("spark.connect.SparkConnectService.ExecutePlan is not implemented"))
}

func (UnimplementedSparkConnectServiceHandler) AnalyzePlan(context.Context, *connect.Request[proto.AnalyzePlanRequest]) (*connect.Response[proto.AnalyzePlanResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("spark.connect.SparkConnectService.AnalyzePlan is not implemented"))
}

func (UnimplementedSparkConnectServiceHandler) Config(context.Context, *connect.Request[proto.ConfigRequest]) (*connect.Response[proto.ConfigResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("spark.connect.SparkConnectService.Config is not implemented"))
}

func (UnimplementedSparkConnectServiceHandler) AddArtifacts(context.Context, *connect.ClientStream[proto.AddArtifactsRequest]) (*connect.Response[proto.AddArtifactsResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("spark.connect.SparkConnectService.AddArtifacts is not implemented"))
}

func (UnimplementedSparkConnectServiceHandler) ArtifactStatus(context.Context, *connect.Request[proto.ArtifactStatusesRequest]) (*connect.Response[proto.ArtifactStatusesResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("spark.connect.SparkConnectService.ArtifactStatus is not implemented"))
}

func (UnimplementedSparkConnectServiceHandler) Interrupt(context.Context, *connect.Request[proto.InterruptRequest]) (*connect.Response[proto.InterruptResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("spark.connect.SparkConnectService.Interrupt is not implemented"))
}

func (UnimplementedSparkConnectServiceHandler) ReattachExecute(context.Context, *connect.Request[proto.ReattachExecuteRequest], *connect.ServerStream[proto.ExecutePlanResponse]) error {
	return connect.NewError(connect.CodeUnimplemented, errors.New("spark.connect.SparkConnectService.ReattachExecute is not implemented"))
}

func (UnimplementedSparkConnectServiceHandler) ReleaseExecute(context.Context, *connect.Request[proto.ReleaseExecuteRequest]) (*connect.Response[proto.ReleaseExecuteResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("spark.connect.SparkConnectService.ReleaseExecute is not implemented"))
}

func (UnimplementedSparkConnectServiceHandler) ReleaseSession(context.Context, *connect.Request[proto.ReleaseSessionRequest]) (*connect.Response[proto.ReleaseSessionResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("spark.connect.SparkConnectService.ReleaseSession is not implemented"))
}

func (UnimplementedSparkConnectServiceHandler) FetchErrorDetails(context.Context, *connect.Request[proto.FetchErrorDetailsRequest]) (*connect.Response[proto.FetchErrorDetailsResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("spark.connect.SparkConnectService.FetchErrorDetails is not implemented"))
}
